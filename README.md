# ğŸ’¬ SupportSphere â€“ RAG-Powered Customer Support Assistant

SupportSphere is an AI-driven customer-support assistant built using Retrieval-Augmented Generation (RAG).  
It combines a Streamlit chat UI, Pinecone vector search, Sentence Transformers embeddings, and FLAN-T5-Large to deliver fast, accurate, and human-like responses.

---

## âœ¨ Features

- **RAG-based answers** (Pinecone + MiniLM embeddings)
- **FLAN-T5-Large text generation** for detailed, conversational responses
- **Modern chat UI**
  - Dark theme with user/assistant bubbles
  - â€œSupportSphere is thinkingâ€¦â€ spinner
  - Typing-style effect for the latest bot answer
- **Escalation to human agent** (logs stored in CSV)
- **Data ingestion pipeline** to index customer-support answers in Pinecone
- **FAQ viewer** in sidebar

---

## ğŸ§± Project Structure

```text
SupportSphere/
â”œâ”€ app.py                     # Streamlit frontend: UI, chat, typing effect, spinner
â”œâ”€ rag_pipeline.py            # Retrieval + generation pipeline (Pinecone + FLAN-T5)
â”œâ”€ ingest_to_pinecone.py      # Encode dataset and upload vectors to Pinecone
â”œâ”€ config.py                  # App title/tagline, ESCALATION_LOG, FAQS_FILE, etc.
â”œâ”€ requirements.txt           # Python dependencies
â”œâ”€ .env                       # Local environment variables (NOT committed)
â”œâ”€ data/
â”‚   â””â”€ faqs.json              # Optional additional FAQ dataset
â”œâ”€ logs/
â”‚   â””â”€ escalations.csv        # Auto-generated escalation records
â””â”€ .gitignore                 # Excludes venv, logs, .env, caches, etc.
```

---

## âš™ï¸ Setup & Installation

### 1. Clone the repository

```bash
git clone https://github.com/<your-username>/SupportSphere.git
cd SupportSphere
```

### 2. Create and activate a virtual environment

**Windows**

```bash
python -m venv venv
venv\Scripts\activate
```

**Linux / macOS**

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

Your `requirements.txt` should include (at minimum):

```text
streamlit
pandas
python-dotenv
sentence-transformers
transformers
torch
pinecone-client
datasets
```

Add any extra libraries you use.

---

## ğŸ”‘ Environment Variables

Create a `.env` file in the project root:

```text
PINECONE_API_KEY=your_api_key
PINECONE_REGION=us-east-1
PINECONE_INDEX_NAME=supportsphere-better
PINECONE_NAMESPACE=support
```

---

## ğŸ§­ Ingest Data Into Pinecone

```bash
python ingest_to_pinecone.py
```

---

## â–¶ï¸ Run the Chatbot

```bash
streamlit run app.py
```

Access at:

```text
http://localhost:8501
```

---

## ğŸ“ Escalation Logging

Logged to:

```text
logs/escalations.csv
```

---

## ğŸŒ Deployment (Streamlit Community Cloud)

Add these secrets under **Settings â†’ Secrets**:

```toml
PINECONE_API_KEY = "your_api_key"
PINECONE_REGION = "us-east-1"
PINECONE_INDEX_NAME = "supportsphere-better"
PINECONE_NAMESPACE = "support"
```

---
